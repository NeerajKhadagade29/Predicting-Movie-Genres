{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Predicting the movie genres</center>\n",
    "___\n",
    "\n",
    "## Abstract\n",
    "> From a long time, movies have been an amazing source of entertainment. It has given a chance for family members to enjoy together, for friends to socialize and for artists to display their talents, be it an actor/actress, directors, cinematographer, dialogue writers and so on. Movies have been a visual art that focuses on storytelling, communicating ideas, stimulate different experiences(like romance, anger, travel, etc.)\n",
    "\n",
    "> In the initial years of filming, films were recorded on a celluloid film through a photochemical process. Since movies are nothing but continuous series of pictures, there were no possibility to include sounds with the moving frames. As humans progressed, learned new techniques to record and display movies, we transitioned to large movie projectors. This gave us a chance to include sound to our motion-pictures. And in no time, we transioned to the era of digital cameras which eased the efforts or recording a movie along with the sound. \n",
    "\n",
    "> I have been a fan of movies, as it gave me an opportunity to look at the world in a broader perspective. I am not a detective, but Sherlock Holmes enlightened me to the world of detectives. I am not a stockbroker, but The Wolf Of Wall Street gave me deep insights to what it takes to be a one. I have never learned or studied mythology, but The Ramayana educated me with it's prolonged history and it's importance.\n",
    "___\n",
    "\n",
    "## Introduction\n",
    "#### 1. Problem Statement\n",
    "> Movies have a range of genres; from romance to sci-fi to drama to comedy and so on. In this notebook, I will try to **predict the genres** of the movies based on _title, tagline, original_title_ and _overview_. With us, we have a dataset of about 45000 movies with metadata collected from IMDB and complied on Kaggle (https://www.kaggle.com/rounakbanik/the-movies-dataset).\n",
    "\n",
    "#### 2. Key Documents\n",
    ">  Out of the 7 documents, as directed, we would only use **movies_metadata.csv**.\n",
    "\n",
    "#### 3. Breakdown of this notebook\n",
    "  > 1. Importing Libraries\n",
    "  2. Loading the dataset\n",
    "  3. Remove/filling the NaN values from the datasets.\n",
    "  4. Cleaning the dataset\n",
    "  6. Classification Analysis:\n",
    "    1. Decision Tree Classifier\n",
    "    2. Random Forest Classifier\n",
    "    3. Multi-layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Importing the metadata of movies\n",
    "df1 = pd.read_csv('movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b> \n",
    "    \n",
    "- According to the problem statement, we need only the following columns:\n",
    "    1. title, \n",
    "    2. tagline\n",
    "    3. original_title\n",
    "    4. overview \n",
    "    5. genres\n",
    "    \n",
    "  Hence, we subset these columns into a new dataframe.\n",
    "</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1[['title', 'tagline', 'original_title', 'overview', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting `title` as the index\n",
    "df.set_index('title',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagline           25054\n",
       "original_title        0\n",
       "overview            954\n",
       "genres                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genre(s) of any movie can be identified by its reviews or description. Here, we have a feature `overview` and we  will use this to predict the genre(s) of the movies.\n",
    "\n",
    "Hence, if for any instance there is *no overview present*, we shall *drop* that partcular instance(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset = ['overview'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extracting the `genres` of each film(row) present in the list of dictionery/ies under the **key** `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "df['genres'] = df['genres'].apply(literal_eval).apply(lambda x: [i['name'] for i in x] \n",
    "                                                                   if isinstance(x, list) else [])\n",
    "                                                                # List Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://www.kaggle.com/rounakbanik/movie-recommender-systems, In [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the following code is to *excluded* any such instances where the genres absent or is '[ ]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only those rows which have an actual genre\n",
    "genre_present = df['genres'] != '[]'\n",
    "\n",
    "# Series of the genres present in the movies_metadata\n",
    "genres = df['genres'][genre_present]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Separating and selecting the genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "labels = mlb.fit_transform(genres)\n",
    "label_classes = mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://datascience.stackexchange.com/questions/11797/split-a-list-of-values-into-columns-of-a-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Aniplex', 'BROSTA TV',\n",
       "       'Carousel Productions', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
       "       'Family', 'Fantasy', 'Foreign', 'GoHands', 'History', 'Horror',\n",
       "       'Mardock Scramble Production Committee', 'Music', 'Mystery',\n",
       "       'Odyssey Media', 'Pulser Productions', 'Rogue State', 'Romance',\n",
       "       'Science Fiction', 'Sentai Filmworks', 'TV Movie',\n",
       "       'Telescene Film Group Productions', 'The Cartel', 'Thriller',\n",
       "       'Vision View Entertainment', 'War', 'Western'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.DataFrame(labels, columns=label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = {}\n",
    "for x in label_classes :\n",
    "    val.update({x:label_data[x].value_counts()[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the `genres` according to the number of instances in *ascending* order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_val = sorted(val.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pd = pd.DataFrame.from_dict(sorted_val, orient='columns')\n",
    "val_pd.rename(columns={0: \"Genre\", 1: \"Count\"}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>20023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>12806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Romance</td>\n",
       "      <td>6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Action</td>\n",
       "      <td>6565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Horror</td>\n",
       "      <td>4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Crime</td>\n",
       "      <td>4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>3886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Family</td>\n",
       "      <td>2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Animation</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Music</td>\n",
       "      <td>1588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>History</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>War</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Western</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>TV Movie</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Aniplex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>BROSTA TV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Carousel Productions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>GoHands</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Mardock Scramble Production Committee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Odyssey Media</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Pulser Productions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Rogue State</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Sentai Filmworks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Telescene Film Group Productions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>The Cartel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Vision View Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Genre  Count\n",
       "0                                   Drama  20023\n",
       "1                                  Comedy  12806\n",
       "2                                Thriller   7586\n",
       "3                                 Romance   6673\n",
       "4                                  Action   6565\n",
       "5                                  Horror   4660\n",
       "6                                   Crime   4269\n",
       "7                             Documentary   3886\n",
       "8                               Adventure   3470\n",
       "9                         Science Fiction   3028\n",
       "10                                 Family   2732\n",
       "11                                Mystery   2451\n",
       "12                                Fantasy   2290\n",
       "13                              Animation   1920\n",
       "14                                Foreign   1599\n",
       "15                                  Music   1588\n",
       "16                                History   1379\n",
       "17                                    War   1310\n",
       "18                                Western   1035\n",
       "19                               TV Movie    751\n",
       "20                                Aniplex      1\n",
       "21                              BROSTA TV      1\n",
       "22                   Carousel Productions      1\n",
       "23                                GoHands      1\n",
       "24  Mardock Scramble Production Committee      1\n",
       "25                          Odyssey Media      1\n",
       "26                     Pulser Productions      1\n",
       "27                            Rogue State      1\n",
       "28                       Sentai Filmworks      1\n",
       "29       Telescene Film Group Productions      1\n",
       "30                             The Cartel      1\n",
       "31              Vision View Entertainment      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at those rows, we notice that the `genres` with value count 1 do not seem to be genres. They seem to be names of production houses or TV channels.\n",
    "\n",
    "Hence we would drop these rows to reduce our search space.\n",
    "___\n",
    "\n",
    "Conversely, we can select the top 20 `genres` from the above data frame for prediction which contain the actual genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 20023),\n",
       " ('Comedy', 12806),\n",
       " ('Thriller', 7586),\n",
       " ('Romance', 6673),\n",
       " ('Action', 6565),\n",
       " ('Horror', 4660),\n",
       " ('Crime', 4269),\n",
       " ('Documentary', 3886),\n",
       " ('Adventure', 3470),\n",
       " ('Science Fiction', 3028),\n",
       " ('Family', 2732),\n",
       " ('Mystery', 2451),\n",
       " ('Fantasy', 2290),\n",
       " ('Animation', 1920),\n",
       " ('Foreign', 1599),\n",
       " ('Music', 1588),\n",
       " ('History', 1379),\n",
       " ('War', 1310),\n",
       " ('Western', 1035),\n",
       " ('TV Movie', 751)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_counts = sorted(val.items(), key=lambda kv: kv[1], reverse=True)[0:20] # Selecting the first 20 genres.\n",
    "dummy_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we select only the first top 20 genres from a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Comprehension\n",
    "genre_counts = [i[0] for i in dummy_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama',\n",
       " 'Comedy',\n",
       " 'Thriller',\n",
       " 'Romance',\n",
       " 'Action',\n",
       " 'Horror',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Adventure',\n",
       " 'Science Fiction',\n",
       " 'Family',\n",
       " 'Mystery',\n",
       " 'Fantasy',\n",
       " 'Animation',\n",
       " 'Foreign',\n",
       " 'Music',\n",
       " 'History',\n",
       " 'War',\n",
       " 'Western',\n",
       " 'TV Movie']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On filtering the actual list of genres, we can now proceed for further processing.\n",
    "___\n",
    "Binarizing the selected genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_genres = MultiLabelBinarizer(classes = genre_counts) \n",
    "# 'genre_counts' is the final list of genres that will be used for futher training ot model\n",
    "\n",
    "top = final_genres.fit(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:930: UserWarning: unknown class(es) ['Aniplex', 'BROSTA TV', 'Carousel Productions', 'GoHands', 'Mardock Scramble Production Committee', 'Odyssey Media', 'Pulser Productions', 'Rogue State', 'Sentai Filmworks', 'Telescene Film Group Productions', 'The Cartel', 'Vision View Entertainment'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    }
   ],
   "source": [
    "# Dependent Variable\n",
    "y = final_genres.transform(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Drama', 'Comedy', 'Thriller', 'Romance', 'Action', 'Horror',\n",
       "       'Crime', 'Documentary', 'Adventure', 'Science Fiction', 'Family',\n",
       "       'Mystery', 'Fantasy', 'Animation', 'Foreign', 'Music', 'History',\n",
       "       'War', 'Western', 'TV Movie'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_genres.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b> \n",
    "    \n",
    "- The genres excluded in the genre_counts will be ignored while implementing MultiLabelBinarizer.\n",
    "  \n",
    "</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, the genre(s) of any movie can be identified by its reviews or description. Here, we have a feature `overview` and we  will use this to predict the genre(s) of the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Separaring the independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Variable\n",
    "X = df['overview']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENSION**\n",
    "\n",
    "If we have a review present but there is no genre present, this would mistrain our predictive model. Therefore for training, we would include only those rows which contains actual genres and not '[ ]'\n",
    "\n",
    "One of the simplest ways to perform this action is to check the sum of each row in the genres after executing the MultiLabelBinarizer. If the sum equals 0, this proves that the particular movie has no genres mentioned . Hence, we would not include them in the training purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including only those rows\n",
    "no_label_classes = y.sum(axis = 1) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X[~no_label_classes], y[~no_label_classes],\n",
    "                                                     test_size = 0.3, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29626,), (29626, 20))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12698,), (12698, 20))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the genres would be predicted based on the `overview`. \n",
    "\n",
    "The steps that we follow are as following:\n",
    "  1. Convert the overview rows into TF-IDF features using TfidfVectorizer\n",
    "  2. Train and build a multi-class classification model\n",
    "  3. Predict the genres of the given overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 1000, stop_words = 'english', lowercase = True)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_valid_vec = vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<29626x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 374765 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have _vectorized_ the `overview` columns and are done with preprocessing steps, we can now build our predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "___\n",
    "Since we build a classification model, we would build the following models:\n",
    "1. Decision Tree Classifier\n",
    "2. Random Forest Classifier\n",
    "\n",
    "On researching on multiclass classification, I found out about **MLPClassifer**. \n",
    "\n",
    "The advantage of MLP Classifier is this implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values. Being out training credentials are sparse matrix and numpy arrays, this would, intuitively, help build a better classification model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model_building(model, parameters = None, cv = 10):\n",
    "    if parameters == None:\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        return(model, model.predict(X_train_vec), model.predict(X_valid_vec))\n",
    "    else:\n",
    "        model_cv = GridSearchCV(estimator = model, param_grid = parameters, cv = cv)\n",
    "        model_cv.fit(X_train_vec, y_train)\n",
    "        model = model_cv.best_estimator_\n",
    "            \n",
    "        return(model_cv,model, model.predict(X_train_vec), model.predict(X_valid_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtr = DecisionTreeClassifier()\n",
    "model, train_dtr, valid_dtr = model_building(dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Drama       1.00      0.99      1.00     14045\n",
      "         Comedy       1.00      0.99      0.99      8960\n",
      "       Thriller       1.00      1.00      1.00      5322\n",
      "        Romance       1.00      1.00      1.00      4646\n",
      "         Action       1.00      1.00      1.00      4585\n",
      "         Horror       1.00      1.00      1.00      3314\n",
      "          Crime       1.00      0.99      1.00      2976\n",
      "    Documentary       1.00      1.00      1.00      2731\n",
      "      Adventure       1.00      1.00      1.00      2420\n",
      "Science Fiction       1.00      1.00      1.00      2122\n",
      "         Family       1.00      0.99      1.00      1916\n",
      "        Mystery       1.00      1.00      1.00      1722\n",
      "        Fantasy       1.00      0.99      1.00      1619\n",
      "      Animation       1.00      0.99      0.99      1335\n",
      "        Foreign       1.00      0.99      0.99      1142\n",
      "          Music       1.00      0.99      1.00      1140\n",
      "        History       1.00      0.99      1.00       951\n",
      "            War       1.00      1.00      1.00       916\n",
      "        Western       1.00      1.00      1.00       711\n",
      "       TV Movie       1.00      1.00      1.00       528\n",
      "\n",
      "      micro avg       1.00      0.99      1.00     63101\n",
      "      macro avg       1.00      0.99      1.00     63101\n",
      "   weighted avg       1.00      0.99      1.00     63101\n",
      "    samples avg       0.99      0.99      0.99     63101\n",
      "\n",
      "Validation:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.56      0.58      0.57      5978\n",
      "         Comedy       0.42      0.41      0.42      3846\n",
      "       Thriller       0.34      0.30      0.32      2264\n",
      "        Romance       0.32      0.29      0.30      2027\n",
      "         Action       0.32      0.25      0.28      1980\n",
      "         Horror       0.32      0.31      0.31      1346\n",
      "          Crime       0.31      0.25      0.27      1293\n",
      "    Documentary       0.47      0.47      0.47      1155\n",
      "      Adventure       0.19      0.13      0.15      1050\n",
      "Science Fiction       0.33      0.26      0.29       906\n",
      "         Family       0.18      0.14      0.16       816\n",
      "        Mystery       0.19      0.13      0.16       729\n",
      "        Fantasy       0.14      0.10      0.11       671\n",
      "      Animation       0.20      0.15      0.17       585\n",
      "        Foreign       0.03      0.02      0.02       457\n",
      "          Music       0.22      0.18      0.20       448\n",
      "        History       0.13      0.10      0.11       428\n",
      "            War       0.30      0.27      0.28       394\n",
      "        Western       0.19      0.15      0.17       324\n",
      "       TV Movie       0.03      0.02      0.03       223\n",
      "\n",
      "      micro avg       0.38      0.34      0.36     26920\n",
      "      macro avg       0.26      0.22      0.24     26920\n",
      "   weighted avg       0.36      0.34      0.35     26920\n",
      "    samples avg       0.41      0.38      0.36     26920\n",
      "\n",
      "Accuracy\n",
      "Traning:  0.9921015324377236\n",
      "Validation:  0.09914947235785163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(\"Classification Report\")\n",
    "print(\"Training:\\n\",classification_report(y_true = y_train, y_pred = train_dtr, target_names = genre_counts))\n",
    "print(\"Validation:\\n\",classification_report(y_true = y_valid, y_pred = valid_dtr, target_names = genre_counts))\n",
    "\n",
    "print(\"Accuracy\")\n",
    "train_dtr_acc = accuracy_score(y_true = y_train, y_pred = train_dtr)\n",
    "valid_dtr_acc = accuracy_score(y_true = y_valid, y_pred = valid_dtr)\n",
    "print(\"Traning: \", train_dtr_acc)\n",
    "print(\"Validation: \",valid_dtr_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "model, train_rfc, valid_rfc = model_building(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.99      0.97      0.98     14045\n",
      "         Comedy       1.00      0.92      0.95      8960\n",
      "       Thriller       1.00      0.88      0.94      5322\n",
      "        Romance       1.00      0.88      0.94      4646\n",
      "         Action       1.00      0.87      0.93      4585\n",
      "         Horror       1.00      0.88      0.93      3314\n",
      "          Crime       1.00      0.86      0.92      2976\n",
      "    Documentary       1.00      0.92      0.96      2731\n",
      "      Adventure       1.00      0.81      0.89      2420\n",
      "Science Fiction       1.00      0.85      0.92      2122\n",
      "         Family       1.00      0.80      0.89      1916\n",
      "        Mystery       1.00      0.79      0.88      1722\n",
      "        Fantasy       1.00      0.79      0.88      1619\n",
      "      Animation       1.00      0.82      0.90      1335\n",
      "        Foreign       1.00      0.72      0.84      1142\n",
      "          Music       1.00      0.82      0.90      1140\n",
      "        History       1.00      0.76      0.87       951\n",
      "            War       1.00      0.85      0.92       916\n",
      "        Western       1.00      0.77      0.87       711\n",
      "       TV Movie       1.00      0.73      0.84       528\n",
      "\n",
      "      micro avg       1.00      0.88      0.94     63101\n",
      "      macro avg       1.00      0.83      0.91     63101\n",
      "   weighted avg       1.00      0.88      0.94     63101\n",
      "    samples avg       0.95      0.90      0.91     63101\n",
      "\n",
      "Validation:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.62      0.56      0.59      5978\n",
      "         Comedy       0.62      0.22      0.32      3846\n",
      "       Thriller       0.48      0.09      0.16      2264\n",
      "        Romance       0.55      0.14      0.22      2027\n",
      "         Action       0.55      0.07      0.12      1980\n",
      "         Horror       0.59      0.12      0.21      1346\n",
      "          Crime       0.60      0.10      0.17      1293\n",
      "    Documentary       0.79      0.40      0.53      1155\n",
      "      Adventure       0.38      0.01      0.02      1050\n",
      "Science Fiction       0.72      0.13      0.23       906\n",
      "         Family       0.54      0.02      0.04       816\n",
      "        Mystery       0.36      0.01      0.03       729\n",
      "        Fantasy       0.75      0.01      0.03       671\n",
      "      Animation       0.81      0.04      0.08       585\n",
      "        Foreign       0.00      0.00      0.00       457\n",
      "          Music       0.57      0.06      0.11       448\n",
      "        History       0.62      0.01      0.02       428\n",
      "            War       0.76      0.06      0.12       394\n",
      "        Western       0.80      0.04      0.07       324\n",
      "       TV Movie       0.00      0.00      0.00       223\n",
      "\n",
      "      micro avg       0.62      0.22      0.32     26920\n",
      "      macro avg       0.56      0.11      0.15     26920\n",
      "   weighted avg       0.58      0.22      0.27     26920\n",
      "    samples avg       0.41      0.27      0.30     26920\n",
      "\n",
      "Accuracy\n",
      "Traning:  0.8366637413083102\n",
      "Validation:  0.1319105370924555\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(\"Training:\\n\",classification_report(y_true = y_train, y_pred = train_rfc, target_names = genre_counts))\n",
    "print(\"Validation:\\n\",classification_report(y_true = y_valid, y_pred = valid_rfc, target_names = genre_counts))\n",
    "\n",
    "print(\"Accuracy\")\n",
    "train_rfc_acc = accuracy_score(y_true = y_train, y_pred = train_rfc)\n",
    "valid_rfc_acc = accuracy_score(y_true = y_valid, y_pred = valid_rfc)\n",
    "print(\"Traning: \", train_rfc_acc)\n",
    "print(\"Validation: \",valid_rfc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.23082559\n",
      "Iteration 2, loss = 5.50312092\n",
      "Iteration 3, loss = 4.96829456\n",
      "Iteration 4, loss = 4.63997070\n",
      "Iteration 5, loss = 4.45528650\n",
      "Iteration 6, loss = 4.34615616\n",
      "Iteration 7, loss = 4.27404513\n",
      "Iteration 8, loss = 4.22148260\n",
      "Iteration 9, loss = 4.18064685\n",
      "Iteration 10, loss = 4.14656685\n",
      "Iteration 11, loss = 4.11892843\n",
      "Iteration 12, loss = 4.09274439\n",
      "Iteration 13, loss = 4.06829769\n",
      "Iteration 14, loss = 4.04702925\n",
      "Iteration 15, loss = 4.02641867\n",
      "Iteration 16, loss = 4.00678114\n",
      "Iteration 17, loss = 3.98803531\n",
      "Iteration 18, loss = 3.96986845\n",
      "Iteration 19, loss = 3.95239979\n",
      "Iteration 20, loss = 3.93536530\n",
      "Iteration 21, loss = 3.91928780\n",
      "Iteration 22, loss = 3.90432368\n",
      "Iteration 23, loss = 3.88850654\n",
      "Iteration 24, loss = 3.87370825\n",
      "Iteration 25, loss = 3.85927359\n",
      "Iteration 26, loss = 3.84532451\n",
      "Iteration 27, loss = 3.83101334\n",
      "Iteration 28, loss = 3.81759384\n",
      "Iteration 29, loss = 3.80371635\n",
      "Iteration 30, loss = 3.79032064\n",
      "Iteration 31, loss = 3.77720875\n",
      "Iteration 32, loss = 3.76349786\n",
      "Iteration 33, loss = 3.75109186\n",
      "Iteration 34, loss = 3.73885391\n",
      "Iteration 35, loss = 3.72501222\n",
      "Iteration 36, loss = 3.71171845\n",
      "Iteration 37, loss = 3.70000624\n",
      "Iteration 38, loss = 3.68807081\n",
      "Iteration 39, loss = 3.67399278\n",
      "Iteration 40, loss = 3.66127681\n",
      "Iteration 41, loss = 3.64815490\n",
      "Iteration 42, loss = 3.63549551\n",
      "Iteration 43, loss = 3.62267841\n",
      "Iteration 44, loss = 3.61001948\n",
      "Iteration 45, loss = 3.59689602\n",
      "Iteration 46, loss = 3.58359414\n",
      "Iteration 47, loss = 3.57007377\n",
      "Iteration 48, loss = 3.55669009\n",
      "Iteration 49, loss = 3.54297576\n",
      "Iteration 50, loss = 3.52919016\n",
      "Iteration 51, loss = 3.51646897\n",
      "Iteration 52, loss = 3.50256798\n",
      "Iteration 53, loss = 3.48812128\n",
      "Iteration 54, loss = 3.47403074\n",
      "Iteration 55, loss = 3.46044017\n",
      "Iteration 56, loss = 3.44575515\n",
      "Iteration 57, loss = 3.43164621\n",
      "Iteration 58, loss = 3.41677122\n",
      "Iteration 59, loss = 3.40264835\n",
      "Iteration 60, loss = 3.38830849\n",
      "Iteration 61, loss = 3.37358060\n",
      "Iteration 62, loss = 3.35836338\n",
      "Iteration 63, loss = 3.34419846\n",
      "Iteration 64, loss = 3.32919561\n",
      "Iteration 65, loss = 3.31399251\n",
      "Iteration 66, loss = 3.29865012\n",
      "Iteration 67, loss = 3.28391411\n",
      "Iteration 68, loss = 3.26857086\n",
      "Iteration 69, loss = 3.25268049\n",
      "Iteration 70, loss = 3.23701456\n",
      "Iteration 71, loss = 3.22256130\n",
      "Iteration 72, loss = 3.20676514\n",
      "Iteration 73, loss = 3.19115092\n",
      "Iteration 74, loss = 3.17527822\n",
      "Iteration 75, loss = 3.15964318\n",
      "Iteration 76, loss = 3.14440687\n",
      "Iteration 77, loss = 3.12930266\n",
      "Iteration 78, loss = 3.11310086\n",
      "Iteration 79, loss = 3.09686883\n",
      "Iteration 80, loss = 3.08129096\n",
      "Iteration 81, loss = 3.06554423\n",
      "Iteration 82, loss = 3.05035013\n",
      "Iteration 83, loss = 3.03335374\n",
      "Iteration 84, loss = 3.01801450\n",
      "Iteration 85, loss = 3.00253155\n",
      "Iteration 86, loss = 2.98544925\n",
      "Iteration 87, loss = 2.97049482\n",
      "Iteration 88, loss = 2.95483576\n",
      "Iteration 89, loss = 2.93870194\n",
      "Iteration 90, loss = 2.92323838\n",
      "Iteration 91, loss = 2.90819338\n",
      "Iteration 92, loss = 2.89177770\n",
      "Iteration 93, loss = 2.87599725\n",
      "Iteration 94, loss = 2.86072715\n",
      "Iteration 95, loss = 2.84404777\n",
      "Iteration 96, loss = 2.82872839\n",
      "Iteration 97, loss = 2.81367201\n",
      "Iteration 98, loss = 2.79835536\n",
      "Iteration 99, loss = 2.78297827\n",
      "Iteration 100, loss = 2.76710998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "### MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(verbose = True, max_iter = 100, hidden_layer_sizes=(100))\n",
    "\n",
    "model, train_mlp, valid_mlp = model_building(mlp, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "Training:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.81      0.83      0.82     14045\n",
      "         Comedy       0.83      0.68      0.75      8960\n",
      "       Thriller       0.81      0.57      0.67      5322\n",
      "        Romance       0.81      0.53      0.64      4646\n",
      "         Action       0.84      0.65      0.73      4585\n",
      "         Horror       0.86      0.65      0.74      3314\n",
      "          Crime       0.80      0.56      0.66      2976\n",
      "    Documentary       0.93      0.78      0.85      2731\n",
      "      Adventure       0.87      0.44      0.58      2420\n",
      "Science Fiction       0.86      0.61      0.71      2122\n",
      "         Family       0.88      0.50      0.63      1916\n",
      "        Mystery       0.84      0.41      0.55      1722\n",
      "        Fantasy       0.84      0.42      0.56      1619\n",
      "      Animation       0.91      0.55      0.68      1335\n",
      "        Foreign       0.81      0.10      0.17      1142\n",
      "          Music       0.89      0.59      0.71      1140\n",
      "        History       0.91      0.41      0.56       951\n",
      "            War       0.91      0.68      0.78       916\n",
      "        Western       0.95      0.73      0.83       711\n",
      "       TV Movie       0.93      0.20      0.32       528\n",
      "\n",
      "      micro avg       0.83      0.64      0.72     63101\n",
      "      macro avg       0.86      0.54      0.65     63101\n",
      "   weighted avg       0.84      0.64      0.71     63101\n",
      "    samples avg       0.79      0.67      0.70     63101\n",
      "\n",
      "Validation:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.64      0.67      0.65      5978\n",
      "         Comedy       0.57      0.46      0.51      3846\n",
      "       Thriller       0.48      0.34      0.40      2264\n",
      "        Romance       0.51      0.33      0.40      2027\n",
      "         Action       0.50      0.37      0.43      1980\n",
      "         Horror       0.55      0.42      0.47      1346\n",
      "          Crime       0.51      0.35      0.41      1293\n",
      "    Documentary       0.71      0.60      0.65      1155\n",
      "      Adventure       0.40      0.18      0.25      1050\n",
      "Science Fiction       0.59      0.41      0.48       906\n",
      "         Family       0.46      0.25      0.33       816\n",
      "        Mystery       0.34      0.16      0.22       729\n",
      "        Fantasy       0.35      0.18      0.23       671\n",
      "      Animation       0.46      0.25      0.33       585\n",
      "        Foreign       0.08      0.01      0.02       457\n",
      "          Music       0.44      0.28      0.34       448\n",
      "        History       0.28      0.09      0.14       428\n",
      "            War       0.52      0.40      0.45       394\n",
      "        Western       0.56      0.36      0.44       324\n",
      "       TV Movie       0.10      0.02      0.03       223\n",
      "\n",
      "      micro avg       0.56      0.42      0.48     26920\n",
      "      macro avg       0.45      0.31      0.36     26920\n",
      "   weighted avg       0.53      0.42      0.46     26920\n",
      "    samples avg       0.53      0.47      0.46     26920\n",
      "\n",
      "Accuracy\n",
      "Traning:  0.3593127658138122\n",
      "Validation:  0.14955111041108837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(\"Training:\\n\",classification_report(y_true = y_train, y_pred = train_mlp, target_names = genre_counts))\n",
    "print(\"Validation:\\n\",classification_report(y_true = y_valid, y_pred = valid_mlp, target_names = genre_counts))\n",
    "\n",
    "print(\"Accuracy\")\n",
    "train_mlp_acc = accuracy_score(y_true = y_train, y_pred = train_mlp)\n",
    "valid_mlp_acc = accuracy_score(y_true = y_valid, y_pred = valid_mlp)\n",
    "print(\"Traning: \", train_mlp_acc)\n",
    "print(\"Validation: \",valid_mlp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics' Dataframe\n",
    "train_acc = [train_dtr_acc, train_rfc_acc, train_mlp_acc]\n",
    "valid_acc = [valid_dtr_acc, valid_rfc_acc, valid_mlp_acc]\n",
    "eval_mat = pd.DataFrame([train_acc, valid_acc],  index = ['Traning','Validation'],\n",
    "                        columns = ['Decision Tree Classifier', 'Random Forest Classifier', 'MLP Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Traning</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.992102</td>\n",
       "      <td>0.099149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.836664</td>\n",
       "      <td>0.131911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>0.359313</td>\n",
       "      <td>0.149551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Traning  Validation\n",
       "Decision Tree Classifier  0.992102    0.099149\n",
       "Random Forest Classifier  0.836664    0.131911\n",
       "MLP Classifier            0.359313    0.149551"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_mat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    " - As we know the characteristic of **Decision trees**, they tend to *overfit* the traning dataset (as it can be seen above too) and perfomance is measured on the validation dataset. We can clearly see that **Decision Tree Classifier** fails to perform well on the validation dataset.\n",
    " \n",
    " - **Random Forest** is a bagging algorithm and has a better control on over-fitting. Here, we can see that **Random Forest Classifier** has better performance that decision tree.\n",
    " \n",
    " - **Multi-layer Perceptron (MLP)** is based on neural networks and uses a supervised learning technique called backpropagation for training. In the above dataframe, we can clearly see that **MLP Classifier** performs the best among the 3.\n",
    " \n",
    "____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the predicted genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = final_genres.inverse_transform(valid_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Comedy'],\n",
       " ['Drama', 'Thriller', 'Crime'],\n",
       " ['Drama', 'Comedy'],\n",
       " ['Drama'],\n",
       " ['Documentary'],\n",
       " ['Drama', 'Comedy'],\n",
       " ['Drama', 'Comedy', 'Romance'],\n",
       " ['Drama'],\n",
       " ['Comedy'],\n",
       " ['Comedy', 'Science Fiction']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(i) for i in test_preds][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges Faced\n",
    "\n",
    "1. Extracting genres from the list of dictionaries present in the feature genres.\n",
    "2. Selecting the right method to convert multi-class labels\n",
    "3. Selecting the right classification algorithm\n",
    "4. Evaluation metrics\n",
    "5. Combining the validation dataset after predicting the genres\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Scope\n",
    "\n",
    "1. Hyper parameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
